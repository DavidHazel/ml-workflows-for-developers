{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the spam generator becomes more intelligent and begins producing prose which looks \"more legitimate\" than before. \n",
    "\n",
    "There are numerous ways the prose could become more like legitimate text. For the purpose of this notebook we will simply force the spam data to 'drift' by adding the first few lines of Pride and Prejudice to the start of the spam documents in our testing set. We will then see how the trained model responds.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/ml-workflows-for-developers/lib/python3.6/site-packages/pyarrow/pandas_compat.py:708: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels = getattr(columns, 'labels', None) or [\n",
      "/anaconda2/envs/ml-workflows-for-developers/lib/python3.6/site-packages/pyarrow/pandas_compat.py:735: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  return pd.MultiIndex(levels=new_levels, labels=labels, names=columns.names)\n",
      "/anaconda2/envs/ml-workflows-for-developers/lib/python3.6/site-packages/pyarrow/pandas_compat.py:752: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"data/training.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into training and testing sets, as in the modelling notebooks. We use the 'random_state' parameter to ensure that the data is split in the same way as it was when we fit the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "df_train, df_test = model_selection.train_test_split(df, random_state=43)\n",
    "df_test_spam = df_test[df_test.label == 'spam'].copy() #filter the spam documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text(doc, adds):\n",
    "    \"\"\"\n",
    "    takes in a string _doc_ and\n",
    "    appends text _adds_ to the start\n",
    "    \"\"\"\n",
    "    \n",
    "    return adds + doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pride_pred = '''It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters.“My dear Mr. Bennet,” said his lady to him one day, “have you heard that Netherfield Park is let at last?” Mr. Bennet replied that he had not. “But it is,” returned she; “for Mrs. Long has just been here, and she told me all about it.” Mr. Bennet made no answer. “Do you not want to know who has taken it?” cried his wife impatiently.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending text to the start of the spam\n",
    "df_test_spam[\"text\"] = df_test_spam.text.apply(add_text, adds=pride_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33863</th>\n",
       "      <td>13863</td>\n",
       "      <td>spam</td>\n",
       "      <td>It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters.“My dear Mr. Bennet,” said his lady to him one day, “have you heard that Netherfield Park is let at last?” Mr. Bennet replied that he had not. “But it is,” returned she; “for Mrs. Long has just been here, and she told me all about it.” Mr. Bennet made no answer. “Do you not want to know who has taken it?” cried his wife impatiently.I've fed her premium brands and a few glowing ones. I am definitely getting this for my Girlfriend's Dad as a birthday gift of these chocolates are good enough to eat! Doesn't taste like fertilizer like another brand of juice. The batch I received wasn't old, and as for taste, it's equivalent to one fruit in the cranberry flavor so much I made a loaf with free shipping using their coupon. Believe me, you will never go back. I was excited about receiving decaf tea, but it is worth the effort. I have eaten some pretty strange things to kill carb cravings, and most of the time, I decant them for draining and make an excellent main course coffee too.Enjoy. The added advantage of dental hygiene is great. At first I was concerned about the crash but there is an easy review: put it in a shake and it tastes bold, like a Cabernet should. If you are looking for an oil to soak toothpicks in like we use to wrap and make Kimbab, Onigiri wraps or Sushi.. I realize that taste is a hit with my kitty, and it is now a once-a-week dinner in our house. There are usually three qualities of matcha: ceremonial, universal, and culinary. Very fine alfalfa seed, very helpful and it gives a sour taste.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21835</th>\n",
       "      <td>1835</td>\n",
       "      <td>spam</td>\n",
       "      <td>It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters.“My dear Mr. Bennet,” said his lady to him one day, “have you heard that Netherfield Park is let at last?” Mr. Bennet replied that he had not. “But it is,” returned she; “for Mrs. Long has just been here, and she told me all about it.” Mr. Bennet made no answer. “Do you not want to know who has taken it?” cried his wife impatiently.Looking forward to trying out some of the dark/bold flavors and even he says they contain anthocyanins which in his words,help you to lose weight or just eat it by the case at all. Full body and not harsh when left in the gym and my workouts are great, I am so addicted to these!!! You know the end of the class--in addition to small treats after each run. Her stool is also firm again.I am now going to have to do is follow the size and so spicy, you can't eat just one? The type in which organic apple juice concentrate. Phat Beets are a different, gourmet style.The Phat Beets recipe has a complex layering of spices--rosemary, ginger, lemon, onion, allspice, cinnamon sticks, cloves and brown sugar oatmeal. However, unlike the Irish, I can only surmise that something has happened to this brand? We recently adopted a 15 lb. If you want to look for it elsewhere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38633</th>\n",
       "      <td>18633</td>\n",
       "      <td>spam</td>\n",
       "      <td>It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters.“My dear Mr. Bennet,” said his lady to him one day, “have you heard that Netherfield Park is let at last?” Mr. Bennet replied that he had not. “But it is,” returned she; “for Mrs. Long has just been here, and she told me all about it.” Mr. Bennet made no answer. “Do you not want to know who has taken it?” cried his wife impatiently.This company is gouging you people!! The product itself - however, I only had one! It is the only low fat cheddar flavored cracker that I am not sure what flavor it was. It's also a little more than others but, as a previous reviewer about adding a can of this into a smoothie that is different than heavy packed snow.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index label  \\\n",
       "33863  13863  spam   \n",
       "21835  1835   spam   \n",
       "38633  18633  spam   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \n",
       "33863  It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters.“My dear Mr. Bennet,” said his lady to him one day, “have you heard that Netherfield Park is let at last?” Mr. Bennet replied that he had not. “But it is,” returned she; “for Mrs. Long has just been here, and she told me all about it.” Mr. Bennet made no answer. “Do you not want to know who has taken it?” cried his wife impatiently.I've fed her premium brands and a few glowing ones. I am definitely getting this for my Girlfriend's Dad as a birthday gift of these chocolates are good enough to eat! Doesn't taste like fertilizer like another brand of juice. The batch I received wasn't old, and as for taste, it's equivalent to one fruit in the cranberry flavor so much I made a loaf with free shipping using their coupon. Believe me, you will never go back. I was excited about receiving decaf tea, but it is worth the effort. I have eaten some pretty strange things to kill carb cravings, and most of the time, I decant them for draining and make an excellent main course coffee too.Enjoy. The added advantage of dental hygiene is great. At first I was concerned about the crash but there is an easy review: put it in a shake and it tastes bold, like a Cabernet should. If you are looking for an oil to soak toothpicks in like we use to wrap and make Kimbab, Onigiri wraps or Sushi.. I realize that taste is a hit with my kitty, and it is now a once-a-week dinner in our house. There are usually three qualities of matcha: ceremonial, universal, and culinary. Very fine alfalfa seed, very helpful and it gives a sour taste.  \n",
       "21835  It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters.“My dear Mr. Bennet,” said his lady to him one day, “have you heard that Netherfield Park is let at last?” Mr. Bennet replied that he had not. “But it is,” returned she; “for Mrs. Long has just been here, and she told me all about it.” Mr. Bennet made no answer. “Do you not want to know who has taken it?” cried his wife impatiently.Looking forward to trying out some of the dark/bold flavors and even he says they contain anthocyanins which in his words,help you to lose weight or just eat it by the case at all. Full body and not harsh when left in the gym and my workouts are great, I am so addicted to these!!! You know the end of the class--in addition to small treats after each run. Her stool is also firm again.I am now going to have to do is follow the size and so spicy, you can't eat just one? The type in which organic apple juice concentrate. Phat Beets are a different, gourmet style.The Phat Beets recipe has a complex layering of spices--rosemary, ginger, lemon, onion, allspice, cinnamon sticks, cloves and brown sugar oatmeal. However, unlike the Irish, I can only surmise that something has happened to this brand? We recently adopted a 15 lb. If you want to look for it elsewhere...                                                                                                                                                                                                                                                                                                                                       \n",
       "38633  It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters.“My dear Mr. Bennet,” said his lady to him one day, “have you heard that Netherfield Park is let at last?” Mr. Bennet replied that he had not. “But it is,” returned she; “for Mrs. Long has just been here, and she told me all about it.” Mr. Bennet made no answer. “Do you not want to know who has taken it?” cried his wife impatiently.This company is gouging you people!! The product itself - however, I only had one! It is the only low fat cheddar flavored cracker that I am not sure what flavor it was. It's also a little more than others but, as a previous reviewer about adding a can of this into a smoothie that is different than heavy packed snow.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1) #ensures that all the text is visible\n",
    "df_test_spam.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to compute the feature vectors for the 'drifted' spam data. We will do this twice: once for the tf_idf feature vectors, and one for the simple summary feature vectors, and compare the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### functions to compute 'simple' summary statistics\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "def strip_punct(doc):\n",
    "    \"\"\"\n",
    "    takes in a document _doc_ and\n",
    "    returns a tuple of the punctuation-free\n",
    "    _doc_ and the count of punctuation in _doc_\n",
    "    \"\"\"\n",
    "    \n",
    "    return re.subn(r\"\"\"[!.><:;',@#~{}\\[\\]\\-_+=£$%^&()?]\"\"\", \"\", doc, count=0, flags=0)\n",
    "\n",
    "def caps(word):\n",
    "    return not word.islower()\n",
    "\n",
    "def isstopword(word):\n",
    "    return word in ENGLISH_STOP_WORDS\n",
    "\n",
    "def standard_summary(row):\n",
    "    \"\"\"\n",
    "    takes in an entry _row_ from the data and \n",
    "    computes each of the summaries then returns\n",
    "    the summaries in a tuple, along with the unique \n",
    "    'level_0' id\n",
    "    \"\"\"\n",
    "    \n",
    "    doc = row[\"text\"]\n",
    "\n",
    "    no_punct = strip_punct(doc)\n",
    "    \n",
    "    words = no_punct[0].split()\n",
    "    \n",
    "    number_words = len(words)\n",
    "    \n",
    "    word_length = [len(x) for x in words]\n",
    "    \n",
    "    mean_wl = sum(word_length)/number_words\n",
    "    \n",
    "    max_wl = max(word_length)\n",
    "    min_wl = min(word_length)\n",
    "\n",
    "    pc_90_wl = np.percentile(word_length, 90)\n",
    "    pc_10_wl = np.percentile(word_length, 10)\n",
    "    \n",
    "    upper = sum([caps(x) for x in words])\n",
    "    stop_words = sum([isstopword(x) for x in words])\n",
    "\n",
    "    return [ no_punct[1], number_words, mean_wl, max_wl, min_wl, pc_10_wl, pc_90_wl, upper, stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_test_spam.apply(standard_summary, axis=1).apply(pd.Series)\n",
    "features.columns = [\"num_punct\", \"num_words\", \"av_wl\", \"max_wl\", \"min_wl\", \"10_quantile\", \"90_quantile\", \"upper_case\", \"stop_words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_punct</th>\n",
       "      <th>num_words</th>\n",
       "      <th>av_wl</th>\n",
       "      <th>max_wl</th>\n",
       "      <th>min_wl</th>\n",
       "      <th>10_quantile</th>\n",
       "      <th>90_quantile</th>\n",
       "      <th>upper_case</th>\n",
       "      <th>stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20027</th>\n",
       "      <td>40.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>4.175000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35121</th>\n",
       "      <td>37.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>4.108696</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26715</th>\n",
       "      <td>40.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>4.239819</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21754</th>\n",
       "      <td>42.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>4.180077</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_punct  num_words     av_wl  max_wl  min_wl  10_quantile  \\\n",
       "20027  40.0       240.0      4.175000  15.0    1.0     2.0           \n",
       "35121  37.0       230.0      4.108696  13.0    1.0     2.0           \n",
       "26715  40.0       221.0      4.239819  13.0    1.0     2.0           \n",
       "21754  42.0       261.0      4.180077  18.0    1.0     2.0           \n",
       "\n",
       "       90_quantile  upper_case  stop_words  \n",
       "20027  8.0          34.0        120.0       \n",
       "35121  7.0          24.0        115.0       \n",
       "26715  8.0          28.0        112.0       \n",
       "21754  7.0          34.0        131.0       "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load in the models we generated earlier and see how well they classify these feature vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/lr_model_simplesummaries.sav' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict(features.iloc[:,0:features.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['legitimate', 'legitimate', 'legitimate', ..., 'legitimate',\n",
       "       'legitimate', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['legitimate', 'spam'],\n",
       "       [3804, 1192]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.unique(predictions, return_counts = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before data drift, this model classified 4142 of the spam documents correctly and 864 incorrectly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compute the tf_idf feature vectors for this drifted data and see if the model performs any better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "hv = HashingVectorizer(norm=None, token_pattern='(?u)\\\\b[A-Za-z]\\\\w+\\\\b', n_features=8192, alternate_sign = False)\n",
    "hvcounts = hv.fit_transform(df_test_spam[\"text\"])\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "hvdf_tfidf = tfidf_transformer.fit_transform(hvcounts)\n",
    "dense_tf_idf = hvdf_tfidf.toarray()\n",
    "tf_features = pd.concat([df_test_spam.reset_index()[[\"index\", \"label\"]],pd.DataFrame(dense_tf_idf)], axis=1)\n",
    "tf_features.columns = tf_features.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8182</th>\n",
       "      <th>8183</th>\n",
       "      <th>8184</th>\n",
       "      <th>8185</th>\n",
       "      <th>8186</th>\n",
       "      <th>8187</th>\n",
       "      <th>8188</th>\n",
       "      <th>8189</th>\n",
       "      <th>8190</th>\n",
       "      <th>8191</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>4355</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>2186</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>6348</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3405</th>\n",
       "      <td>7826</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>12290</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>15235</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>766</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>17409</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4349</th>\n",
       "      <td>19539</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>14698</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 8194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index label    0    1    2    3    4    5    6    7  ...      8182  \\\n",
       "1736  4355   spam  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.191259   \n",
       "3593  2186   spam  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "1396  6348   spam  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "3405  7826   spam  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "1261  12290  spam  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "782   15235  spam  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "637   766    spam  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "2378  17409  spam  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "4349  19539  spam  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "730   14698  spam  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "\n",
       "      8183  8184  8185  8186  8187  8188  8189  8190  8191  \n",
       "1736  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3593  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1396  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3405  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1261  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "782   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "637   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2378  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4349  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "730   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "[10 rows x 8194 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_features.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/lr_model_tfidfsummaries.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict(tf_features.iloc[:,2:tf_features.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam', 'legitimate', 'legitimate', ..., 'legitimate',\n",
       "       'legitimate', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['legitimate', 'spam'],\n",
       "       [3807, 1189]], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(np.unique(predictions, return_counts = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "The two models perform very similarly on the 'drifted' data in this notebook. Consider alternative types of data drift and see how the models perform: \n",
    "1. What happens when fewer words from Pride and Prejudice are appended to the spam? \n",
    "2. How about using a completely different exert of Austen? \n",
    "3. How do the models perform when generic text (neither Austen nor food reviews) is appended to the spam? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
