{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interacting with model services\n",
    "\n",
    "We've seen how to deploy machine learning pipelines into production with `s2i` and now we'll see how we can use these services to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "import json\n",
    "\n",
    "DEFAULT_BASE_URL = \"http://localhost:8080/%s\"\n",
    "\n",
    "def score_text(text, url = None):\n",
    "    url = (url or (DEFAULT_BASE_URL % \"predict\")) \n",
    "    if type(text) == str:\n",
    "        text = [text]\n",
    "    payload = urlencode({\"json_args\" : json.dumps(text)})\n",
    "    headers = {'content-type': 'application/x-www-form-urlencoded'}\n",
    "    response = requests.request(\"POST\", url, data=payload, headers=headers)\n",
    "    return json.loads(response.text)\n",
    "\n",
    "def get_metrics(url = None):\n",
    "    def parse_one_metric(line):\n",
    "        ll = line.rsplit(' ', 1)\n",
    "        return (ll[0], float(ll[1]))\n",
    "    \n",
    "    url = (url or (DEFAULT_BASE_URL % \"metrics\")) \n",
    "    response = requests.request(\"POST\", url)\n",
    "    return dict([parse_one_metric(line) for line in response.text.split('\\n') if len(line) > 0 and line[0] != '#'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['legitimate']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_text(\"It is a truth universally acknowledged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'python_gc_objects_collected_total{generation=\"0\"}': 717.0, 'python_gc_objects_collected_total{generation=\"1\"}': 35.0, 'python_gc_objects_collected_total{generation=\"2\"}': 0.0, 'python_gc_objects_uncollectable_total{generation=\"0\"}': 0.0, 'python_gc_objects_uncollectable_total{generation=\"1\"}': 0.0, 'python_gc_objects_uncollectable_total{generation=\"2\"}': 0.0, 'python_gc_collections_total{generation=\"0\"}': 249.0, 'python_gc_collections_total{generation=\"1\"}': 22.0, 'python_gc_collections_total{generation=\"2\"}': 2.0, 'python_info{implementation=\"CPython\",major=\"3\",minor=\"6\",patchlevel=\"6\",version=\"3.6.6\"}': 1.0, 'process_virtual_memory_bytes': 650973184.0, 'process_resident_memory_bytes': 104599552.0, 'process_start_time_seconds': 1556740178.16, 'process_cpu_seconds_total': 1.65, 'process_open_fds': 11.0, 'process_max_fds': 1048576.0, 'pipeline_processing_seconds_count': 20.0, 'pipeline_processing_seconds_sum': 0.3145384999952512, 'pipeline_processing_seconds_created': 1556740179.2619493, 'pipeline_predictions_total{value=\"legitimate\"}': 16.0, 'pipeline_predictions_total{value=\"spam\"}': 3.0, 'pipeline_predictions_created{value=\"legitimate\"}': 1556740272.4946618, 'pipeline_predictions_created{value=\"spam\"}': 1556740278.5537658}\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
